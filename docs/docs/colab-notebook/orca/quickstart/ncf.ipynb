{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ncf.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM43TZhsccEPZaQgFY1DvGW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Le-Zheng/analytics-zoo/blob/ncfdataframe/docs/docs/colab-notebook/orca/quickstart/ncf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsdUyI7vKEGF"
      },
      "source": [
        "\r\n",
        "![image.png](data:image/png;base64,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)\r\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQWPKGb4KNv6"
      },
      "source": [
        "## **Environment Preparation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwxHGCOQKToI"
      },
      "source": [
        "**Install Java 8**\r\n",
        "\r\n",
        "Run the cell on the **Google Colab** to install jdk 1.8.\r\n",
        "\r\n",
        "**Note:** if you run this notebook on your computer, root permission is required when running the cell to install Java 8. (You may ignore this cell if Java 8 has already been set up in your computer)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV2cU3jJIXCg"
      },
      "source": [
        "# Install jdk8\r\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\r\n",
        "import os\r\n",
        "# Set environment variable JAVA_HOME.\r\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\r\n",
        "!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\r\n",
        "!java -version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDMnBeFSKz21"
      },
      "source": [
        "**Install Analytics Zoo**\r\n",
        "\r\n",
        "You can install the latest release version or latest pre-release version using `pip install --pre  analytics-zoo`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FKTQXbDYWWr"
      },
      "source": [
        "# Install latest release version of analytics-zoo \r\n",
        "# Installing analytics-zoo from pip will automatically install pyspark, bigdl, and their dependencies.\r\n",
        "!pip install --pre analytics-zoo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MmD2EAQYatg"
      },
      "source": [
        "# Install python dependencies\r\n",
        "!pip install tensorflow==1.15.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zy-92WBjYdx5"
      },
      "source": [
        "## **NCF (data preprocessing with Spark Dataframes)** \r\n",
        "\r\n",
        "In this guide we will describe how to use Spark Dataframes to process large-scale dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAy37CZkYy3p"
      },
      "source": [
        "#### **Intialization** \r\n",
        "\r\n",
        "import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mNCKlZLY5xI"
      },
      "source": [
        "import os\r\n",
        "import zipfile\r\n",
        "import argparse\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "from bigdl.dataset import base\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "from zoo.orca import init_orca_context, stop_orca_context\r\n",
        "from zoo.orca import OrcaContext\r\n",
        "from zoo.orca.learn.tf.estimator import Estimator\r\n",
        "from zoo.orca.data import SharedValue\r\n",
        "import zoo.orca.data.pandas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kU0wwMFgY9hs"
      },
      "source": [
        "## **Init Orca Context** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InTPPklsZMNW"
      },
      "source": [
        "# recommended to set it to True when running Analytics Zoo in Jupyter notebook \r\n",
        "OrcaContext.log_output = True # (this will display terminal's stdout and stderr in the Jupyter notebook).\r\n",
        "\r\n",
        "cluster_mode = \"local\"\r\n",
        "\r\n",
        "if cluster_mode == \"local\":  \r\n",
        "    init_orca_context(cluster_mode=\"local\", cores=4) # run in local mode\r\n",
        "elif cluster_mode == \"yarn\":  \r\n",
        "    init_orca_context(cluster_mode=\"yarn-client\", num_nodes=2, cores=2, driver_memory=\"6g\") # run on Hadoop YARN cluster"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dO2x4TI4ZRnq"
      },
      "source": [
        "## **Data Preprocessing with Spark Dataframes**\r\n",
        "\r\n",
        "Orca supports Spark Dataframes as the input to the distributed training, and as the input/output of the distributed inference. Consequently, the user can easily process large-scale dataset using Apache Spark, and directly apply AI models on the distributed (and possibly in-memory) Dataframes without data conversion or serialization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xyxitSDZP8V"
      },
      "source": [
        "# Download and extract movielens 1M data.\r\n",
        "url = 'http://files.grouplens.org/datasets/movielens/ml-1m.zip'\r\n",
        "local_file = base.maybe_download('ml-1m.zip', '.', url)\r\n",
        "if not os.path.exists('./ml-1m'):\r\n",
        "        zip_ref = zipfile.ZipFile(local_file, 'r')\r\n",
        "        zip_ref.extractall('.')\r\n",
        "        zip_ref.close()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxeY0f2Ia7yo"
      },
      "source": [
        "# Read in the dataset, and do a little preprocessing\r\n",
        "rating_files=\"./ml-1m/ratings.dat\"\r\n",
        "new_rating_files=\"./ml-1m/ratings_new.dat\"\r\n",
        "if not os.path.exists(new_rating_files):\r\n",
        "        fin = open(rating_files, \"rt\")\r\n",
        "        fout = open(new_rating_files, \"wt\")\r\n",
        "        for line in fin:\r\n",
        "            # replace :: to : for spark 2.4 support\r\n",
        "            fout.write(line.replace('::', ':'))\r\n",
        "        fin.close()\r\n",
        "        fout.close()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BVhLa-ebFTe",
        "outputId": "12084926-504f-4bf7-8699-6f13353642ea"
      },
      "source": [
        "# read csv\r\n",
        "from zoo.common.nncontext import *\r\n",
        "sc = init_nncontext()\r\n",
        "sqlcontext = SQLContext(sc)\r\n",
        "df = sqlcontext.read.csv(new_rating_files, sep=':', header=True, inferSchema=True).toDF(\r\n",
        "  \"user\", \"item\", \"label\", \"timestamp\")\r\n",
        "\r\n",
        "user_set = df.select('user').collect()\r\n",
        "item_set = df.select('item').collect()\r\n",
        "\r\n",
        "min_user_id = min(user_set)[0]\r\n",
        "max_user_id = max(user_set)[0]\r\n",
        "min_item_id = min(item_set)[0]\r\n",
        "max_item_id = max(item_set)[0]\r\n",
        "print(min_user_id, max_user_id, min_item_id, max_item_id)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1 6040 1 3952\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFLTccOlbTaa"
      },
      "source": [
        "# update label starting from 0\r\n",
        "df = df.withColumn('label', df.label-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXym4BodbzwS"
      },
      "source": [
        "# split to train/test dataset\r\n",
        "train_data, test_data = df.randomSplit([0.8, 0.2])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEgxpdYcb7oC"
      },
      "source": [
        "### **Define NCF Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnPGNXK0b8ot"
      },
      "source": [
        "class NCF(object):\r\n",
        "    def __init__(self, embed_size, user_size, item_size):\r\n",
        "        self.user = tf.placeholder(dtype=tf.int32, shape=(None,))\r\n",
        "        self.item = tf.placeholder(dtype=tf.int32, shape=(None,))\r\n",
        "        self.label = tf.placeholder(dtype=tf.int32, shape=(None,))\r\n",
        "\r\n",
        "        with tf.name_scope(\"GMF\"):\r\n",
        "            user_embed_GMF = tf.contrib.layers.embed_sequence(self.user,\r\n",
        "                                                              vocab_size=user_size + 1,\r\n",
        "                                                              embed_dim=embed_size,\r\n",
        "                                                              unique=False\r\n",
        "                                                              )\r\n",
        "            item_embed_GMF = tf.contrib.layers.embed_sequence(self.item,\r\n",
        "                                                              vocab_size=item_size + 1,\r\n",
        "                                                              embed_dim=embed_size,\r\n",
        "                                                              unique=False\r\n",
        "                                                              )\r\n",
        "            GMF = tf.multiply(user_embed_GMF, item_embed_GMF, name='GMF')\r\n",
        "\r\n",
        "        # MLP part starts\r\n",
        "        with tf.name_scope(\"MLP\"):\r\n",
        "            user_embed_MLP = tf.contrib.layers.embed_sequence(self.user,\r\n",
        "                                                              vocab_size=user_size + 1,\r\n",
        "                                                              embed_dim=embed_size,\r\n",
        "                                                              unique=False,\r\n",
        "                                                              )\r\n",
        "\r\n",
        "            item_embed_MLP = tf.contrib.layers.embed_sequence(self.item,\r\n",
        "                                                              vocab_size=item_size + 1,\r\n",
        "                                                              embed_dim=embed_size,\r\n",
        "                                                              unique=False\r\n",
        "                                                              )\r\n",
        "            interaction = tf.concat([user_embed_MLP, item_embed_MLP],\r\n",
        "                                    axis=-1, name='interaction')\r\n",
        "\r\n",
        "            layer1_MLP = tf.layers.dense(inputs=interaction,\r\n",
        "                                         units=embed_size * 2,\r\n",
        "                                         name='layer1_MLP')\r\n",
        "            layer1_MLP = tf.layers.dropout(layer1_MLP, rate=0.2)\r\n",
        "\r\n",
        "            layer2_MLP = tf.layers.dense(inputs=layer1_MLP,\r\n",
        "                                         units=embed_size,\r\n",
        "                                         name='layer2_MLP')\r\n",
        "            layer2_MLP = tf.layers.dropout(layer2_MLP, rate=0.2)\r\n",
        "\r\n",
        "            layer3_MLP = tf.layers.dense(inputs=layer2_MLP,\r\n",
        "                                         units=embed_size // 2,\r\n",
        "                                         name='layer3_MLP')\r\n",
        "            layer3_MLP = tf.layers.dropout(layer3_MLP, rate=0.2)\r\n",
        "\r\n",
        "        # Concate the two parts together\r\n",
        "        with tf.name_scope(\"concatenation\"):\r\n",
        "            concatenation = tf.concat([GMF, layer3_MLP], axis=-1,\r\n",
        "                                      name='concatenation')\r\n",
        "            self.logits = tf.layers.dense(inputs=concatenation,\r\n",
        "                                          units=5,\r\n",
        "                                          name='predict')\r\n",
        "\r\n",
        "            self.logits_softmax = tf.nn.softmax(self.logits)\r\n",
        "\r\n",
        "            self.class_number = tf.argmax(self.logits_softmax, 1)\r\n",
        "\r\n",
        "        with tf.name_scope(\"loss\"):\r\n",
        "            self.loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\r\n",
        "                labels=self.label, logits=self.logits, name='loss'))\r\n",
        "\r\n",
        "        with tf.name_scope(\"optimzation\"):\r\n",
        "            self.optim = tf.train.AdamOptimizer(1e-3, name='Adam')\r\n",
        "            self.optimizer = self.optim.minimize(self.loss)\r\n",
        "\r\n",
        "embedding_size=16\r\n",
        "model = NCF(embedding_size, max_user_id, max_item_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1srWZc5DcHMG"
      },
      "source": [
        "### **Fit with Orca Estimator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqTuXJbYcRj6"
      },
      "source": [
        "batch_size=1280\r\n",
        "epochs=1\r\n",
        "model_dir='./'\r\n",
        "\r\n",
        "# create an Estimator.\r\n",
        "estimator = Estimator.from_graph(\r\n",
        "            inputs=[model.user, model.item],\r\n",
        "            outputs=[model.class_number],\r\n",
        "            labels=[model.label],\r\n",
        "            loss=model.loss,\r\n",
        "            optimizer=model.optim,\r\n",
        "            model_dir=model_dir,\r\n",
        "            metrics={\"loss\": model.loss})\r\n",
        "\r\n",
        "estimator.fit(data=train_data,\r\n",
        "        batch_size=1280,\r\n",
        "        epochs=1,\r\n",
        "        feature_cols=['user', 'item'],\r\n",
        "        label_cols=['label'],\r\n",
        "        validation_data=test_data)\r\n",
        "\r\n",
        "checkpoint_path = os.path.join(model_dir, \"NCF.ckpt\")\r\n",
        "estimator.save_tf_checkpoint(checkpoint_path)\r\n",
        "estimator.sess.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCWgLX-wcfTj",
        "outputId": "841f805c-5b01-4f51-b48a-9e3fb578c3ca"
      },
      "source": [
        "# predict using the Estimator\r\n",
        "\r\n",
        "def predict(predict_data, user_size, item_size):\r\n",
        "\r\n",
        "    predict_data = test.drop(\"label\")\r\n",
        "    tf.reset_default_graph()\r\n",
        "\r\n",
        "    with tf.Session() as sess:\r\n",
        "        model = NCF(embedding_size, user_size, item_size)\r\n",
        "\r\n",
        "        saver = tf.train.Saver(tf.global_variables())\r\n",
        "        checkpoint_path = os.path.join(model_dir, \"NCF.ckpt\")\r\n",
        "        saver.restore(sess, checkpoint_path)\r\n",
        "\r\n",
        "        estimator = Estimator.from_graph(\r\n",
        "            inputs=[model.user, model.item],\r\n",
        "            outputs=[model.class_number],\r\n",
        "            sess=sess,\r\n",
        "            model_dir=model_dir\r\n",
        "        )\r\n",
        "        predict_result = estimator.predict(predict_data, batch_size=1280, feature_cols=['user', 'item'])\r\n",
        "        predict_result.select('prediction').show(10)\r\n",
        "\r\n",
        "predict(test_data, max_user_id, max_item_id)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./NCF.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/zoo/tfpark/tfnet.py:275: simple_save (from tensorflow.python.saved_model.simple_save) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.simple_save.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: /tmp/tmp7arwreq5/saved_model.pb\n",
            "2021-02-01 07:30:31 WARN  TFNetForInference$:234 - Loading TensorFlow SavedModel: SavedModel tag is not defined, using <serve>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-02-01 07:30:31.524850: I tensorflow/cc/saved_model/reader.cc:31] Reading SavedModel from: /tmp/tmp7arwreq5\n",
            "2021-02-01 07:30:31.528883: I tensorflow/cc/saved_model/reader.cc:54] Reading meta graph with tags { serve }\n",
            "2021-02-01 07:30:31.535007: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
            "2021-02-01 07:30:31.549293: I tensorflow/cc/saved_model/loader.cc:202] Restoring SavedModel bundle.\n",
            "2021-02-01 07:30:31.645341: I tensorflow/cc/saved_model/loader.cc:311] SavedModel load for tags { serve }; Status: success. Took 120491 microseconds.\n",
            "[Stage 2585:>                                                       (0 + 1) / 1]Prepending /usr/local/lib/python3.6/dist-packages/bigdl/share/conf/spark-bigdl.conf to sys.path\n",
            "Prepending /usr/local/lib/python3.6/dist-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path\n",
            "Prepending /usr/local/lib/python3.6/dist-packages/bigdl/share/conf/spark-bigdl.conf to sys.path\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 170, in manager\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 73, in worker\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 402, in main\n",
            "    if read_int(infile) == SpecialLengths.END_OF_STREAM:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 717, in read_int\n",
            "    raise EOFError\n",
            "EOFError\n",
            "[Stage 2586:>                                                       (0 + 1) / 1]Prepending /usr/local/lib/python3.6/dist-packages/bigdl/share/conf/spark-bigdl.conf to sys.path\n",
            "Prepending /usr/local/lib/python3.6/dist-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path\n",
            "Prepending /usr/local/lib/python3.6/dist-packages/bigdl/share/conf/spark-bigdl.conf to sys.path\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "+----------+\n",
            "|prediction|\n",
            "+----------+\n",
            "|       3.0|\n",
            "|       3.0|\n",
            "|       4.0|\n",
            "|       3.0|\n",
            "|       3.0|\n",
            "|       3.0|\n",
            "|       3.0|\n",
            "|       3.0|\n",
            "|       3.0|\n",
            "|       3.0|\n",
            "+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 170, in manager\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 73, in worker\n",
            "\r                                                                                \r  File \"/usr/local/lib/python3.6/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 402, in main\n",
            "    if read_int(infile) == SpecialLengths.END_OF_STREAM:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 717, in read_int\n",
            "    raise EOFError\n",
            "EOFError\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeJsTahMgFxE"
      },
      "source": [
        "stop_orca_context()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}